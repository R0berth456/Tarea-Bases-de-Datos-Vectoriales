{
  "cells": [
    {
      "metadata": {
        "id": "bcf314626bfa1d6e"
      },
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 7: Bases de Datos Vectoriales\n",
        "\n",
        "## Objetivo de la práctica\n",
        "\n",
        "Entender el concepto de Bases de Datos Vectoriales y saber utilizar las herramientas actuales"
      ],
      "id": "bcf314626bfa1d6e"
    },
    {
      "metadata": {
        "id": "6969f64a18e27b98"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 0: Carga del Corpus\n",
        "\n",
        "Vamos a utilizar la API de Kaggle para acceder al dataset _Wikipedia Text Corpus for NLP and LLM Projects_\n",
        "\n",
        "El corpus está disponible desde este [link](https://www.kaggle.com/datasets/gzdekzlkaya/wikipedia-text-corpus-for-nlp-and-llm-projects?utm_source=chatgpt.com)\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Carga el corpus\n"
      ],
      "id": "6969f64a18e27b98"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-05T13:56:25.762698Z",
          "start_time": "2026-01-05T13:56:25.007804Z"
        },
        "id": "759acb68ad40d112"
      },
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ],
      "id": "759acb68ad40d112",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-05T13:56:31.775989Z",
          "start_time": "2026-01-05T13:56:25.764830Z"
        },
        "id": "ea5141c83c549f5e"
      },
      "cell_type": "code",
      "source": [
        "# Set the path to the file you'd like to load\n",
        "file_path = \"wikipedia_text_corpus.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.dataset_load(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"gzdekzlkaya/wikipedia-text-corpus-for-nlp-and-llm-projects\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "df.head()"
      ],
      "id": "ea5141c83c549f5e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a000da740833ca58"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 1: Generación de Embeddings\n",
        "\n",
        "Vamos a utilizar E5 como modelo de embeddings.\n",
        "\n",
        "La documentación de E5 está disponible desde este [link](https://huggingface.co/intfloat/e5-base-v2)\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Normalizar el corpus\n",
        "2. Definir una función `chunk_text`, y dividir los textos en _chunks_.\n",
        "3. Generar embeddings por cada _chunk_"
      ],
      "id": "a000da740833ca58"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-05T13:56:33.821456Z",
          "start_time": "2026-01-05T13:56:31.777990Z"
        },
        "id": "639f5ff5b295666d"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "\n",
        "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
        "\n",
        "# Limpieza básica\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "df[\"text_norm\"] = df[\"text\"].astype(str).map(normalize_text)\n",
        "\n",
        "df.head()"
      ],
      "id": "639f5ff5b295666d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-05T13:56:34.604172Z",
          "start_time": "2026-01-05T13:56:33.823452Z"
        },
        "id": "9c97a94faca1c4a1"
      },
      "cell_type": "code",
      "source": [
        "def chunk_text(text: str, max_chars: int = 800, overlap: int = 100):\n",
        "    \"\"\"\n",
        "    Chunking por caracteres.\n",
        "    max_chars ~ 600-1000 suele funcionar bien.\n",
        "    overlap ayuda a no cortar ideas a la mitad.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    n = len(text)\n",
        "    while start < n:\n",
        "        end = min(start + max_chars, n)\n",
        "        chunk = text[start:end]\n",
        "        chunk = chunk.strip()\n",
        "        if len(chunk) > 0:\n",
        "            chunks.append(chunk)\n",
        "        if end == n:\n",
        "            break\n",
        "        start = max(0, end - overlap)\n",
        "    return chunks\n",
        "\n",
        "records = []\n",
        "for i, row in df.iterrows():\n",
        "    chunks = chunk_text(row[\"text_norm\"], max_chars=800, overlap=100)\n",
        "    for j, ch in enumerate(chunks):\n",
        "        records.append({\n",
        "            \"doc_id\": int(i),\n",
        "            \"chunk_id\": j,\n",
        "            \"text\": ch\n",
        "        })\n",
        "\n",
        "chunks_df = pd.DataFrame(records)\n",
        "chunks_df.head(), len(chunks_df)"
      ],
      "id": "9c97a94faca1c4a1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "MODEL_NAME = \"intfloat/e5-base-v2\"   # recomendado para retrieval\n",
        "model = SentenceTransformer(MODEL_NAME)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Chz2feeOU3fa"
      },
      "id": "Chz2feeOU3fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-05T14:00:46.191265Z",
          "start_time": "2026-01-05T14:00:44.216576Z"
        },
        "collapsed": true,
        "id": "69a8183ec2c4767e"
      },
      "cell_type": "code",
      "source": [
        "# Textos a indexar (pasajes)\n",
        "passages = [\"passage: \" + t for t in chunks_df[\"text\"].tolist()]"
      ],
      "id": "69a8183ec2c4767e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "ExecuteTime": {
          "start_time": "2026-01-05T14:02:01.650144Z"
        },
        "id": "cc6f9319fe0075fa"
      },
      "cell_type": "code",
      "source": [
        "# Embeddings (N x D)\n",
        "# Se debe usar normalize_embeddings=True para similitud coseno\n",
        "embeddings = model.encode(\n",
        "    passages,\n",
        "    batch_size=16,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ").astype(\"float32\")"
      ],
      "id": "cc6f9319fe0075fa",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fadd9833"
      },
      "source": [
        "### Guardar los Embeddings"
      ],
      "id": "fadd9833"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "484740c5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_file_path = \"wikipedia_embeddings_e5.npy\"\n",
        "np.save(embeddings_file_path, embeddings)\n",
        "print(f\"Embeddings guardados en: {embeddings_file_path}\")"
      ],
      "id": "484740c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2929b5e2"
      },
      "source": [
        "### Cargar los Embeddings"
      ],
      "id": "2929b5e2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b04aa93"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_file_path = \"wikipedia_embeddings_e5.npy\"\n",
        "\n",
        "# Carga el array de embeddings\n",
        "embeddings = np.load(embeddings_file_path)"
      ],
      "id": "6b04aa93",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f73da34fcbbdd0b9"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(embeddings.shape, embeddings.dtype)"
      ],
      "id": "f73da34fcbbdd0b9"
    },
    {
      "metadata": {
        "id": "1975f9c2556bb8e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def embed_query(query: str) -> np.ndarray:\n",
        "    q = \"query: \" + query\n",
        "    vec = model.encode(\n",
        "        [q],\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "    return vec\n",
        "\n",
        "query_text = \"Battery measuring\"\n",
        "\n",
        "query_embedding = embed_query(query_text)\n",
        "query_embedding.shape"
      ],
      "id": "1975f9c2556bb8e"
    },
    {
      "metadata": {
        "id": "d8fdbebcf1cb69b3"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 2: FAISS\n",
        "\n",
        "FAISS es una librería para búsqueda por similitud eficiente y clustering de vectores densos.\n",
        "\n",
        "La documentación de FAISS está disponible en este [link](https://faiss.ai/index.html)\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Crea un índice en FAISS\n",
        "2. Carga los embeddings\n",
        "3. Realiza una búsqueda a partir de una _query_"
      ],
      "id": "d8fdbebcf1cb69b3"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wYCyx1yqGdxn"
      },
      "id": "wYCyx1yqGdxn",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5097e7479312e742"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# código base para FAISS\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Asumiendo `embeddings` en un array NxD\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "D, I = index.search(query_embedding, k=10)"
      ],
      "id": "5097e7479312e742"
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks_df[\"text\"].iloc[I[0].tolist()])"
      ],
      "metadata": {
        "id": "Cr8QSWVXHTMP"
      },
      "id": "Cr8QSWVXHTMP",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52f15b24eea20878"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 3 — Vector DB #1: Qdrant (búsqueda vectorial + metadata)\n",
        "\n",
        "### Objetivo\n",
        "Recrear el mismo flujo que con FAISS, pero usando una base vectorial con soporte nativo de **metadata** y filtros.\n",
        "\n",
        "### Qué debes implementar\n",
        "1. Levantar / conectar con una instancia de Qdrant.\n",
        "2. Crear una colección con:\n",
        "   - dimensión `D` (la de tus embeddings)\n",
        "   - métrica (cosine o L2)\n",
        "3. Insertar:\n",
        "   - `id`\n",
        "   - `embedding`\n",
        "   - `payload` (metadata: texto, título, etiquetas, etc.)\n",
        "4. Consultar Top-k por similitud:\n",
        "   - `query_embedding`\n",
        "   - `k`\n",
        "\n",
        "### Inputs esperados (ya definidos arriba en el notebook)\n",
        "- `embeddings`: matriz `N x D` (float32)\n",
        "- `texts`: lista de `N` strings\n",
        "- `metadatas`: lista de `N` dicts (opcional)\n",
        "- `query_text`: string\n",
        "- `query_embedding`: vector `1 x D`\n",
        "\n",
        "### Entregable\n",
        "- Una función `qdrant_search(query_embedding, k)` que retorne:\n",
        "  - lista de `(id, score, text, metadata)`\n",
        "- Un ejemplo de consulta con `k=5` y su salida.\n",
        "\n",
        "### Preguntas\n",
        "- ¿La métrica usada fue cosine o L2? ¿Por qué?\n",
        "- ¿Qué tan fácil fue filtrar por metadata en comparación con FAISS?\n",
        "- ¿Qué pasa con el tiempo de respuesta cuando aumentas `k`?\n"
      ],
      "id": "52f15b24eea20878"
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "9ff2a78ffffb7836"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "!pip install -U qdrant-client"
      ],
      "id": "9ff2a78ffffb7836"
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models, QdrantClient\n",
        "\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"wikipedia\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=model.get_sentence_embedding_dimension(),  # Vector size is defined by used model\n",
        "        distance=models.Distance.COSINE,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "XYdzqpj3Lt_V"
      },
      "id": "XYdzqpj3Lt_V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.upload_points(\n",
        "    collection_name=\"wikipedia\",\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=idx,\n",
        "            vector=embeddings[idx].tolist(), # Asigna el embedding correcto para este punto\n",
        "            payload=row.to_dict()           # Convierte la fila del DataFrame a un diccionario para el payload\n",
        "        )\n",
        "        for idx, row in chunks_df.iterrows() # Itera sobre las filas del DataFrame\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "UqtR1fOTMvn1"
      },
      "id": "UqtR1fOTMvn1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hits = client.query_points(\n",
        "    collection_name=\"wikipedia\",\n",
        "    query=query_embedding[0].tolist(),\n",
        "    limit=10,\n",
        ").points\n",
        "\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "id": "ga7TNCJgNnQU"
      },
      "id": "ga7TNCJgNnQU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de la función `qdrant_search(query_embedding, k)`"
      ],
      "metadata": {
        "id": "PLxhzBGvQ99z"
      },
      "id": "PLxhzBGvQ99z"
    },
    {
      "cell_type": "code",
      "source": [
        "def qdrant_search(query_embedding, k):\n",
        "  hits = client.query_points(\n",
        "    collection_name=\"wikipedia\",\n",
        "    query=query_embedding[0].tolist(),\n",
        "    limit=k,\n",
        "  ).points\n",
        "  return hits"
      ],
      "metadata": {
        "id": "NZzT-NXBRWsz"
      },
      "id": "NZzT-NXBRWsz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"multidimensional space\"\n",
        "query_embedding = embed_query(query_text)\n",
        "hits = qdrant_search(query_embedding, k=5)\n",
        "for hit in hits:\n",
        "    print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "id": "xGvTyQnSRkVL"
      },
      "id": "xGvTyQnSRkVL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82edcc06"
      },
      "source": [
        "### Liberación de recursos de RAM"
      ],
      "id": "82edcc06"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f673cd08"
      },
      "source": [
        "import gc\n",
        "\n",
        "# Eliminar el DataFrame original\n",
        "if 'df' in locals():\n",
        "    del df\n",
        "\n",
        "# Eliminar la lista de pasajes\n",
        "if 'passages' in locals():\n",
        "    del passages\n",
        "\n",
        "# Forzar el recolector de basura de Python\n",
        "gc.collect()"
      ],
      "id": "f673cd08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b5ad1e"
      },
      "source": [
        "Eliminar la colección de Qdrant"
      ],
      "id": "e0b5ad1e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b985b618"
      },
      "source": [
        "collection_name = \"wikipedia\"\n",
        "\n",
        "# Verifica si la colección existe antes de intentar eliminarla\n",
        "if client.collection_exists(collection_name):\n",
        "    client.delete_collection(collection_name=collection_name)"
      ],
      "id": "b985b618",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69bec6e05b842dff"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 4 — Vector DB #2: Milvus (indexación ANN y escalabilidad)\n",
        "\n",
        "### Objetivo\n",
        "Implementar el flujo de indexación + búsqueda con una base vectorial orientada a escalabilidad.\n",
        "\n",
        "### Qué debes implementar\n",
        "1. Conectar a Milvus.\n",
        "2. Crear un esquema (colección) con:\n",
        "   - campo `id` (entero o string)\n",
        "   - campo `embedding` (vector `D`)\n",
        "   - campos de metadata (p.ej., `category`, `source`, `title`)\n",
        "3. Insertar `N` embeddings.\n",
        "4. Crear/seleccionar un índice ANN (ej. HNSW o IVF).\n",
        "5. Ejecutar consultas Top-k y recuperar textos asociados.\n",
        "\n",
        "### Recomendación didáctica\n",
        "Haz dos configuraciones:\n",
        "- **Búsqueda exacta** (si aplica) o configuración “más precisa”\n",
        "- **Búsqueda ANN** (configuración “más rápida”)\n",
        "\n",
        "Luego compara:\n",
        "- tiempo de consulta\n",
        "- overlap de resultados (cuántos IDs coinciden)\n",
        "\n",
        "### Entregable\n",
        "- Función `milvus_search(query_embedding, k)` que devuelva resultados.\n",
        "- Un mini experimento: `k=5` y `k=20` (tiempos y resultados).\n",
        "\n",
        "### Preguntas\n",
        "- ¿Qué parámetros del índice/control de búsqueda ajustaste para precisión vs velocidad?\n",
        "- ¿Qué evidencia tienes de que ANN cambia los resultados (aunque sea poco)?\n"
      ],
      "id": "69bec6e05b842dff"
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "2c0ce6b984802eb6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "!pip install -U pymilvus"
      ],
      "id": "2c0ce6b984802eb6"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymilvus[milvus_lite]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vk5Zi2H1UkeK"
      },
      "id": "Vk5Zi2H1UkeK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "\n",
        "client = MilvusClient(\"milvus_demo.db\")"
      ],
      "metadata": {
        "id": "NLn0XPp6Tt3i"
      },
      "id": "NLn0XPp6Tt3i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbee6aa8"
      },
      "source": [
        "COLLECTION_NAME = \"wikipedia\"\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    dimension=embeddings.shape[1],\n",
        "    primary_field_name=\"id\",\n",
        "    vector_field_name=\"embedding\",\n",
        "    auto_id=False,\n",
        ")"
      ],
      "id": "dbee6aa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "256d54e6"
      },
      "source": [
        "milvus_data = []\n",
        "\n",
        "for i, row in chunks_df.iterrows():\n",
        "    milvus_data.append({\n",
        "        \"id\": int(i),\n",
        "        \"embedding\": embeddings[i].tolist(),\n",
        "        \"text\": row[\"text\"],\n",
        "        \"doc_id\": int(row[\"doc_id\"]),\n",
        "        \"chunk_id\": int(row[\"chunk_id\"]),\n",
        "    })"
      ],
      "id": "256d54e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a8f5858"
      },
      "source": [
        "batch_size = 5000\n",
        "\n",
        "for i in range(0, len(milvus_data), batch_size):\n",
        "    batch = milvus_data[i:i + batch_size]\n",
        "    client.insert(collection_name=COLLECTION_NAME, data=batch)\n",
        "    print(f\"Insertados {len(batch)} puntos. Total insertados: {i + len(batch)}\")"
      ],
      "id": "5a8f5858",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def milvus_search(query_embedding, k):\n",
        "  res = client.search(\n",
        "      collection_name=COLLECTION_NAME,  # target collection\n",
        "      data=query_embedding,  # query vectors: debe ser una lista de vectores\n",
        "      limit=k,  # number of returned entities\n",
        "      output_fields=[\"doc_id\", \"chunk_id\", \"text\"],  # specifies fields to be returned\n",
        "  )\n",
        "  return res"
      ],
      "metadata": {
        "id": "R4515rbVc6cA"
      },
      "id": "R4515rbVc6cA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"Battery measuring\"\n",
        "query_embedding = embed_query(query_text)\n",
        "\n",
        "res = milvus_search(query_embedding.tolist(), k=10)\n",
        "for hit in res:\n",
        "  for hitt in hit:\n",
        "    print(hitt)"
      ],
      "metadata": {
        "id": "462AX-30dt7G"
      },
      "id": "462AX-30dt7G",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "749c7459cd31499f"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 5 — Vector DB #3: Weaviate (búsqueda semántica con esquema)\n",
        "\n",
        "### Objetivo\n",
        "Montar una colección con esquema (clase) y ejecutar búsquedas semánticas Top-k, opcionalmente con filtros.\n",
        "\n",
        "### Qué debes implementar\n",
        "1. Conectar a Weaviate.\n",
        "2. Definir un esquema:\n",
        "   - Clase/colección (por ejemplo `Document`)\n",
        "   - Propiedades: `text`, `title`, `category`, etc.\n",
        "   - Vector asociado (embedding)\n",
        "3. Insertar objetos con:\n",
        "   - propiedades + vector\n",
        "4. Consultar por similitud (Top-k) con `query_embedding`.\n",
        "5. (Opcional) agregar un filtro por propiedad (metadata).\n",
        "\n",
        "### Recomendación\n",
        "Asegúrate de guardar el `text` original y al menos 1 campo de metadata para probar filtrado.\n",
        "\n",
        "### Entregable\n",
        "- Función `weaviate_search(query_embedding, k)` que retorne:\n",
        "  - id, score, text, metadata\n",
        "\n",
        "### Preguntas\n",
        "- ¿Qué diferencia conceptual encuentras entre “schema + objetos” vs “tabla + filas”?\n",
        "- ¿Cómo describirías el trade-off de complejidad vs expresividad?\n"
      ],
      "id": "749c7459cd31499f"
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "25195a86a0105c1d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "!pip install -U weaviate-client[agents]"
      ],
      "id": "25195a86a0105c1d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kXzZVH9RjNBd"
      },
      "source": [
        "from weaviate.client import WeaviateClient\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "\n",
        "client = WeaviateClient(\n",
        "    embedded_options=EmbeddedOptions()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "kXzZVH9RjNBd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FZ3bY_bRjNBe"
      },
      "source": [
        "from weaviate.client import WeaviateClient\n",
        "import weaviate.classes as wvc\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"WikipediaChunk\",\n",
        "    properties=[\n",
        "        wvc.config.Property(name=\"text\", data_type=wvc.config.DataType.TEXT),\n",
        "        wvc.config.Property(name=\"doc_id\", data_type=wvc.config.DataType.INT),\n",
        "        wvc.config.Property(name=\"chunk_id\", data_type=wvc.config.DataType.INT)\n",
        "    ],\n",
        "    vector_config=wvc.config.Configure.Vectorizer.none(),\n",
        "    vector_index_config=wvc.config.Configure.VectorIndex.hnsw(\n",
        "        distance_metric=wvc.config.VectorDistances.COSINE\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "FZ3bY_bRjNBe"
    },
    {
      "metadata": {
        "id": "40919fda773f0fbb"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 6 — Vector Store #4: Chroma (prototipado rápido)\n",
        "\n",
        "### Objetivo\n",
        "Implementar la misma idea de indexación y búsqueda semántica con una herramienta ligera de prototipado.\n",
        "\n",
        "### Qué debes implementar\n",
        "1. Crear una colección.\n",
        "2. Insertar:\n",
        "   - ids\n",
        "   - embeddings\n",
        "   - documents (texto)\n",
        "   - metadatas (opcional)\n",
        "3. Consultar Top-k con `query_embedding`.\n",
        "\n",
        "### Nota didáctica\n",
        "Chroma es útil para prototipos: enfócate en reproducir el pipeline sin “infra pesada”.\n",
        "\n",
        "### Entregable\n",
        "- Función `chroma_search(query_embedding, k)` que retorne resultados.\n",
        "- Una consulta con `k=5`.\n",
        "\n",
        "### Preguntas\n",
        "- ¿Qué tan fácil fue implementar todo comparado con Qdrant/Milvus?\n",
        "- ¿Qué limitaciones ves para un sistema en producción?\n"
      ],
      "id": "40919fda773f0fbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7OhjSsB_koBp"
      },
      "source": [
        "!pip install -U chromadb"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7OhjSsB_koBp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRcW5QR6k5Jc"
      },
      "source": [
        "import chromadb\n",
        "\n",
        "client = chromadb.Client()\n",
        "print(\"ChromaDB client initialized in-memory.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "VRcW5QR6k5Jc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9zqa4Bjn5VX"
      },
      "source": [
        "collection_name = \"wikipedia_chunks_chroma\"\n",
        "\n",
        "# Get or create the collection to avoid 'already exists' error\n",
        "collection = client.get_or_create_collection(name=collection_name)\n",
        "print(f\"Collection '{collection_name}' is ready.\")\n",
        "\n",
        "# Prepare data for insertion\n",
        "ids = [str(i) for i in chunks_df.index.tolist()]\n",
        "documents = chunks_df[\"text\"].tolist()\n",
        "\n",
        "metadatas = []\n",
        "for i, row in chunks_df.iterrows():\n",
        "    metadatas.append({\"doc_id\": int(row[\"doc_id\"]), \"chunk_id\": int(row[\"chunk_id\"])}) # Ensure int type for metadata\n",
        "\n",
        "batch_size = 5000 # Using a batch size smaller than the reported max batch size\n",
        "\n",
        "for i in range(0, len(ids), batch_size):\n",
        "    batch_ids = ids[i:i + batch_size]\n",
        "    batch_embeddings = embeddings[i:i + batch_size].tolist()\n",
        "    batch_documents = documents[i:i + batch_size]\n",
        "    batch_metadatas = metadatas[i:i + batch_size]\n",
        "\n",
        "    collection.add(\n",
        "        embeddings=batch_embeddings,\n",
        "        documents=batch_documents,\n",
        "        metadatas=batch_metadatas,\n",
        "        ids=batch_ids\n",
        "    )\n",
        "    print(f\"Inserted {len(batch_ids)} documents. Total inserted: {i + len(batch_ids)}\")\n",
        "\n",
        "print(f\"Finished inserting {len(ids)} documents into '{collection_name}' collection.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "l9zqa4Bjn5VX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761d7138"
      },
      "source": [
        "def chroma_search(query_embedding, k):\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding.tolist(),\n",
        "        n_results=k,\n",
        "        include=['documents', 'distances', 'metadatas']\n",
        "    )\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "761d7138"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bbb07dd"
      },
      "source": [
        "query_text = \"Battery measuring\"\n",
        "query_embedding = embed_query(query_text)\n",
        "\n",
        "hits = chroma_search(query_embedding, k=5)\n",
        "\n",
        "# Print the results in a readable format\n",
        "print(\"ChromaDB Search Results (k=5) for query: 'Battery measuring'\")\n",
        "for i in range(len(hits['ids'][0])):\n",
        "    print(f\"---\\nID: {hits['ids'][0][i]}\\nScore (distance): {hits['distances'][0][i]}\\nText: {hits['documents'][0][i]}\\nMetadata: {hits['metadatas'][0][i]}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2bbb07dd"
    },
    {
      "metadata": {
        "id": "f7b383f0d5f720d"
      },
      "cell_type": "markdown",
      "source": [
        "## Parte 7 — SQL + vectores: PostgreSQL/pgvector (vector search transparente)\n",
        "\n",
        "### Objetivo\n",
        "Guardar embeddings en una tabla y ejecutar una consulta SQL de similitud.\n",
        "\n",
        "### Qué debes implementar\n",
        "1. Conectar a una base PostgreSQL con `pgvector` habilitado.\n",
        "2. Crear una tabla (ej. `documents`) con:\n",
        "   - `id` (PK)\n",
        "   - `text` (texto)\n",
        "   - `embedding` (vector(D))\n",
        "   - metadata (columnas adicionales)\n",
        "3. Insertar todos los documentos y embeddings.\n",
        "4. Consultar Top-k por similitud, ordenando por distancia.\n",
        "\n",
        "### Fórmula conceptual (lo que implementa tu SQL)\n",
        "Para una consulta `q`, buscas:\n",
        "$$ argmin_d \\in D \\; \\text{dist}(\\vec{q}, \\vec{d})$$\n",
        "donde `dist` puede ser L2 o una variante para cosine (según configuración).\n",
        "\n",
        "### Entregable\n",
        "- Función `pgvector_search(query_embedding, k)` que ejecute SQL y devuelva:\n",
        "  - id, score/distancia, text, metadata\n",
        "\n",
        "### Preguntas\n",
        "- ¿Qué tan “explicable” te parece esta aproximación vs las otras?\n",
        "- ¿Qué ventajas ofrece el mundo SQL (JOIN, filtros, agregaciones)?\n",
        "- ¿Qué limitaciones esperas en escalabilidad frente a bases vectoriales dedicadas?\n"
      ],
      "id": "f7b383f0d5f720d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "714680c6"
      },
      "source": [
        "!pip install psycopg2-binary"
      ],
      "id": "714680c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "58c88abb"
      },
      "source": [
        "import psycopg2\n",
        "\n",
        "DB_NAME = \"mydatabase\"\n",
        "DB_USER = \"myuser\"\n",
        "DB_PASSWORD = \"mypassword\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5432\"\n",
        "\n",
        "conn = None\n",
        "cursor = None\n",
        "\n",
        "try:\n",
        "    conn = psycopg2.connect(\n",
        "        dbname=DB_NAME,\n",
        "        user=DB_USER,\n",
        "        password=DB_PASSWORD,\n",
        "        host=DB_HOST,\n",
        "        port=DB_PORT\n",
        "    )\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
        "    conn.commit()\n",
        "\n",
        "finally:\n",
        "    if cursor:\n",
        "        cursor.close()\n",
        "    if conn:\n",
        "        conn.close()\n"
      ],
      "id": "58c88abb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}